# Just Another Word Segmentor (JAWS)

A Khmer word segmentation model based on Graph Neural Networks. It represent pairs of characters as nodes and perform node classification to determined if there is a space between two characters.

### Samples taken from Facebook posts

```
Source: ááŸ‚á”á¾á¢ááŸ‹á›á»á™áŸá„á•á„ á˜á¶á“á›á»á™á”áŸ’áá¹á„áŠáŸ‚á› ?
Output: ááŸ‚ á”á¾ á¢ááŸ‹á›á»á™ áŸá„ á•á„ á˜á¶á“ á›á»á™ á”áŸ’áá¹á„ áŠáŸ‚á› ?

Source: á€á¼á“á‡á¶á”áŸ‹ášáŸ€á“á‘á¶áŸ†á„á¢áŸáŸ‹á‚áŸ’á“á¶á˜á·á“á”á¶á“á‡á¼á“áŠá¾ášá›áŸá„á‘áŸ ááŸ‚á‚áŸ’á˜á¶á“á¢áŸ’áœá¸áŸá”áŸ’á”á¶á™á‡á¶á„á€á¶ášá‡á½á”á‡á»áŸ†á‘áŸ
Output: á€á¼á“ á‡á¶á”áŸ‹ ášáŸ€á“ á‘á¶áŸ†á„ á¢áŸáŸ‹ á‚áŸ’á“á¶ á˜á·á“ á”á¶á“á‡á¼á“ áŠá¾áš á›áŸá„ á‘áŸ ááŸ‚ á‚áŸ’á˜á¶á“ á¢áŸ’áœá¸ áŸá”áŸ’á”á¶á™ á‡á¶á„ á€á¶ášá‡á½á” á‡á»áŸ†á‘áŸ

Source: áŸáŸ’á¢á¶ááá¶áŸáŸ‹á€áŸ’á˜áŸá„áá¼á…
Output: áŸáŸ’á¢á¶á áá¶áŸáŸ‹ á€áŸ’á˜áŸá„ áá¼á…

Source: á…á„áŸ‹á…á¼á›á•áŸ’áá›áŸ‹á€á˜áŸ’á›á¶áŸ†á„á…á·ááŸ’áá“á·á„á‡á½á™áŸáŸ’ášá„áŸ‹á€áŸ’á›á·á“á“á·á„áá¶á”á„
Output: á…á„áŸ‹ á…á¼á› á•áŸ’áá›áŸ‹ á€á˜áŸ’á›á¶áŸ†á„ á…á·ááŸ’á á“á·á„ á‡á½á™ áŸáŸ’ášá„áŸ‹ á€áŸ’á›á·á“ á“á·á„ áá¶á”á„

Source: á€á¶á“áŸ‹ááŸáŸ’ášáŸáŸ‹áŸáŸ’á¢á¶áá”áŸ’á›áŸ‚á€ááŸ‚á˜áŸ’áŠá„á á¾á™ BA á›áŸ€áŸá á¶á›á™á¾á„á áŸ’á“á¹á„
Output: á€á¶á“áŸ‹ ááŸáŸ’ášáŸáŸ‹ áŸáŸ’á¢á¶á á”áŸ’á›áŸ‚á€ ááŸ‚ á˜áŸ’áŠá„ á á¾á™ BA á›áŸ€áŸ á á¶á› á™á¾á„ á áŸ’á“á¹á„

Source: ááŸ’á‰á»áŸ†á€áŸ†á–á»á„á“áŸ…á‡á¶á˜á½á™áá¶á„CMG CCTV áŠá¾á˜áŸ’á”á¸ááá•áŸ’áŸá–áŸ’áœá•áŸ’áŸá¶á™áœá”áŸ’á”á’á˜áŸŒááŸ’á˜áŸ‚ášá‘áŸ…á€á¶á“áŸ‹á–á·á—á–á›áŸ„á€ á¥á¡á¼áœá“áŸáŸ‡ááŸ’á‰á»áŸ†á€áŸ†á–á»á„á˜á¾á›á–áŸ’ášáŸ‡á¢á¶á‘á·ááŸ’á™ášáŸ‡ á“áŸ…á”áŸ’ášá¶áŸá¶á‘á¢á„áŸ’á‚ášáœááŸ’áğŸ‡°ğŸ‡­âœ¨ğŸŒ…
Output: ááŸ’á‰á»áŸ† á€áŸ†á–á»á„ á“áŸ… á‡á¶á˜á½á™ áá¶á„ CMG CCTV áŠá¾á˜áŸ’á”á¸ áá á•áŸ’áŸá–áŸ’áœá•áŸ’áŸá¶á™ áœá”áŸ’á”á’á˜áŸŒ ááŸ’á˜áŸ‚áš á‘áŸ… á€á¶á“áŸ‹ á–á·á—á– á›áŸ„á€ á¥á¡á¼áœ á“áŸáŸ‡ ááŸ’á‰á»áŸ† á€áŸ†á–á»á„ á˜á¾á› á–áŸ’ášáŸ‡ á¢á¶á‘á·ááŸ’á™ ášáŸ‡ á“áŸ… á”áŸ’ášá¶áŸá¶á‘ á¢á„áŸ’á‚áš áœááŸ’á ğŸ‡°ğŸ‡­âœ¨ğŸŒ…

Source: áŸá¼á˜áŸ’á”á¸ááŸ‚áŸá˜áŸ’á›áŸá„á€áŸáˆáŸ’á›áŸ„áŸ‡á‚áŸ’á“á¶áŠáŸ‚áš áˆáŸ’á›áŸ„áŸ‡á‚áŸ’ášá”áŸ‹á™áŸ‰á¶á„ mak Lin ğŸ˜­
Output: áŸá¼á˜áŸ’á”á¸ ááŸ‚ áŸá˜áŸ’á›áŸá„ á€áŸ áˆáŸ’á›áŸ„áŸ‡ á‚áŸ’á“á¶ áŠáŸ‚áš áˆáŸ’á›áŸ„áŸ‡ á‚áŸ’ášá”áŸ‹ á™áŸ‰á¶á„ mak Lin ğŸ˜­

Source: Global Green Growth Week á”á¶á“ááŸ’ášá›á”áŸ‹á˜á€áœá·á‰á á¾á™ á“áŸ…áŸá”áŸ’áá¶á áŸá€áŸ’ášáŸ„á™á“áŸáŸ‡!
Output: Global Green Growth Week á”á¶á“ ááŸ’ášá›á”áŸ‹ á˜á€ áœá·á‰ á á¾á™ á“áŸ… áŸá”áŸ’áá¶á áŸ á€áŸ’ášáŸ„á™ á“áŸáŸ‡ !

Source: á‰á¶ááŸ’áá·á‚á¶áŸ†á‘áŸ’áš Cambodian Pageant á“á·á„á¢áŸ’á“á€á‚á¶áŸ†á‘áŸ’ášáœá·áŸáŸá™á”áœášá€á‰áŸ’á‰á¶á€á˜áŸ’á–á»á‡á¶á…áŸ†á–áŸ„áŸ‡á”áŸ’ášáŸá¶áŸá“áŸá›áŸ„á€áŸáŸ’ášá¸á¢áŸ‰á¹á˜ áŸá»á‚á“áŸ’á’á¶ Sokunthea Im á€áŸ’á“á»á„á€á¶ášá”áŸ’ááŸá‡áŸ’á‰á¶á…á·ááŸ’á áŸáŸ†áá¼á˜á–ášá³áŸ’á™áŸáŸ’áá¶á”áŸá“á–á¶á€áŸ‹á–áŸá“áŸ’á’ á”á·á‘á€á¶ášá”áŸ’ášá€á½á á“á·á„á€á¶ášá”á‰áŸ’á‡á¼á“á”áŸá€áŸ’áá—á¶á–ááŸ†áá¶á„á€á˜áŸ’á–á»á‡á¶á…á¼á›ášá½á˜á”áŸ’ášá€á½á Miss Grand International
Output: á‰á¶ ááŸ’áá· á‚á¶áŸ†á‘áŸ’áš Cambodian Pageant á“á·á„ á¢áŸ’á“á€ á‚á¶áŸ†á‘áŸ’áš áœá·áŸáŸá™ á”áœáš á€á‰áŸ’á‰á¶ á€á˜áŸ’á–á»á‡á¶ á…áŸ†á–áŸ„áŸ‡ á”áŸ’ášáŸá¶áŸá“áŸ á›áŸ„á€ áŸáŸ’ášá¸ á¢áŸ‰á¹á˜ áŸá»á‚á“áŸ’á’á¶ Sokunthea Im á€áŸ’á“á»á„ á€á¶áš á”áŸ’ááŸá‡áŸ’á‰á¶ á…á·ááŸ’á áŸáŸ†áá¼á˜ á–ášá³áŸ’á™ áŸáŸ’áá¶á”áŸá“ á–á¶á€áŸ‹ á–áŸá“áŸ’á’ á”á·á‘ á€á¶áš á”áŸ’ášá€á½á á“á·á„ á€á¶áš á”á‰áŸ’á‡á¼á“ á”áŸá€áŸ’á á—á¶á– ááŸ†áá¶á„ á€á˜áŸ’á–á»á‡á¶ á…á¼á› ášá½á˜ á”áŸ’ášá€á½á Miss Grand International
```

## How to run

### Segment

You can perform word segmentation using the pretrained model by running the below command.

```bash
usage: segment.py [-h] [--file_mode] [--console_output] config model_path sample

Run the segmentation on one sample text file.

positional arguments:
  config            Path to config file.
  model_path        Path to model weight file.
  sample            Path to the input text file containing the text to segment.

optional arguments:
  -h, --help        show this help message and exit
  --file_mode       Wether sample is a file
  --console_output  Whether to output the result to console
```

### Training

The model can be retrained on your custom dataset using the below command.

```bash
usage: train.py [-h] [--output_dir OUTPUT_DIR] [--dataset_type {khpos,phylypo}] [--lr LR] [--early_stopping_patience EARLY_STOPPING_PATIENCE] [--epochs EPOCHS] config dataset_path

Run the training loop.

positional arguments:
  config                Path to config file.
  dataset_path          Path to dataset. (text file if of type khpos or directory if of type phylypo)

optional arguments:
  -h, --help            show this help message and exit
  --output_dir OUTPUT_DIR
                        Path to output directory.
  --dataset_type {khpos,phylypo}
                        The type of dataset to use
  --lr LR               The learning rate
  --early_stopping_patience EARLY_STOPPING_PATIENCE
                        The learning rate
  --epochs EPOCHS       The number of epochs to train
```

### Evaluation

To evaluate a trained model, use the below command.

```bash
usage: evaluate.py [-h] [--output_dir OUTPUT_DIR] [--dataset_type {khpos,phylypo}] config model_path dataset_path

Run the training loop.

positional arguments:
  config                Path to config file.
  model_path            Path to model weight file.
  dataset_path          Path to dataset. (text file if of type khpos or directory if of type phylypo)

optional arguments:
  -h, --help            show this help message and exit
  --output_dir OUTPUT_DIR
                        Path to output directory.
  --dataset_type {khpos,phylypo}
                        The type of dataset to use
```

## About Pretrained Weights

The pretrained weights are available [here](pretrained). Each weights were produced by training using the dataset from KhPOS available [here](https://github.com/ye-kyaw-thu/khPOS).
Below is the results on the test sets from the set repository.

**Open Set**: [here](https://github.com/ye-kyaw-thu/khPOS/blob/master/corpus-draft-ver-1.0/data/OPEN-TEST.word)
| Model | F1 Score | Word Error Rate |
| ------- | -------- | --------------- |
| JAWSGCN | 98.035% | 5.915% |
| JAWSGAT | 98.462% | 4.911% |

**Close Set** [here](https://github.com/ye-kyaw-thu/khPOS/blob/master/corpus-draft-ver-1.0/data/CLOSE-TEST.word)
| Model | F1 Score | Word Error Rate |
| ------- | -------- | --------------- |
| JAWSGCN | 98.814% | 3.855% |
| JAWSGAT | 98.941% | 3.487% |
